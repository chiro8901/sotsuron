"""
Steam ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ã®ã¹ãåˆ†å¸ƒåˆ†æãƒ„ãƒ¼ãƒ«
CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ total_reviews ã‚’èª­ã¿è¾¼ã¿ã€ã¹ãåˆ†å¸ƒã¸ã®é©åˆåº¦ã‚’åˆ†æ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from pathlib import Path

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.sans-serif'] = ['MS Gothic', 'Yu Gothic', 'Meiryo']
plt.rcParams['axes.unicode_minus'] = False

# ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
sns.set_style("whitegrid")
plt.rcParams['figure.dpi'] = 300
plt.rcParams['savefig.dpi'] = 300


def load_review_data(csv_path):
    """CSVã‹ã‚‰ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ã‚’èª­ã¿è¾¼ã¿"""
    print(f"ğŸ“‚ èª­ã¿è¾¼ã¿ä¸­: {csv_path}")
    
    df = pd.read_csv(csv_path)
    
    # total_reviewsåˆ—ã‚’æŠ½å‡º
    reviews = df['total_reviews'].dropna()
    
    # 0ã‚ˆã‚Šå¤§ãã„å€¤ã®ã¿
    reviews = reviews[reviews > 0].astype(int)
    
    print(f"âœ… èª­ã¿è¾¼ã¿å®Œäº†: {len(df):,} è¡Œ")
    print(f"âœ… ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚ã‚Š: {len(reviews):,} ã‚²ãƒ¼ãƒ  ({len(reviews)/len(df)*100:.1f}%)")
    
    return reviews.values


def calculate_power_law_metrics(data):
    """ã¹ãåˆ†å¸ƒã®å„ç¨®æŒ‡æ¨™ã‚’è¨ˆç®—"""
    
    # é™é †ã‚½ãƒ¼ãƒˆ
    sorted_data = np.sort(data)[::-1]
    n = len(sorted_data)
    
    # ãƒ©ãƒ³ã‚¯ä»˜ã‘
    ranks = np.arange(1, n + 1)
    
    # å¯¾æ•°å¤‰æ›
    log_ranks = np.log10(ranks)
    log_values = np.log10(sorted_data)
    
    # ç·šå½¢å›å¸° (log-log)
    slope, intercept, r_value, p_value, std_err = stats.linregress(log_ranks, log_values)
    
    alpha = -slope  # ã¹ãæŒ‡æ•°
    r_squared = r_value ** 2
    
    # Giniä¿‚æ•°
    sorted_asc = np.sort(data)
    n = len(sorted_asc)
    index = np.arange(1, n + 1)
    gini = (2 * np.sum(index * sorted_asc)) / (n * np.sum(sorted_asc)) - (n + 1) / n
    
    # ãƒ‘ãƒ¬ãƒ¼ãƒˆåˆ†æ (ä¸Šä½20%)
    top_20_idx = int(n * 0.2)
    top_20_sum = np.sum(sorted_data[:top_20_idx])
    total_sum = np.sum(sorted_data)
    pareto_ratio = top_20_sum / total_sum
    
    # ä¸Šä½1%, 5%, 10%ã®åˆ†æ
    top_1_sum = np.sum(sorted_data[:max(1, int(n * 0.01))])
    top_5_sum = np.sum(sorted_data[:max(1, int(n * 0.05))])
    top_10_sum = np.sum(sorted_data[:max(1, int(n * 0.10))])
    
    return {
        'alpha': alpha,
        'r_squared': r_squared,
        'gini': gini,
        'pareto_20': pareto_ratio,
        'top_1_pct': top_1_sum / total_sum,
        'top_5_pct': top_5_sum / total_sum,
        'top_10_pct': top_10_sum / total_sum,
        'slope': slope,
        'intercept': intercept,
        'p_value': p_value
    }


def create_analysis_plots(data, metrics, output_path):
    """åˆ†æã‚°ãƒ©ãƒ•ã‚’ä½œæˆ"""
    
    fig = plt.figure(figsize=(16, 12))
    
    sorted_data = np.sort(data)[::-1]
    ranks = np.arange(1, len(sorted_data) + 1)
    
    # 1. åŸºæœ¬åˆ†å¸ƒï¼ˆãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ï¼‰
    ax1 = plt.subplot(3, 3, 1)
    plt.hist(data, bins=50, edgecolor='black', alpha=0.7, color='steelblue')
    plt.xlabel('ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°', fontsize=11)
    plt.ylabel('ã‚²ãƒ¼ãƒ æ•°', fontsize=11)
    plt.title('ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ã®åˆ†å¸ƒ', fontsize=12, fontweight='bold')
    plt.grid(True, alpha=0.3)
    
    # 2. å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
    ax2 = plt.subplot(3, 3, 2)
    plt.hist(data, bins=50, edgecolor='black', alpha=0.7, color='coral')
    plt.xlabel('ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•° (log)', fontsize=11)
    plt.ylabel('ã‚²ãƒ¼ãƒ æ•° (log)', fontsize=11)
    plt.xscale('log')
    plt.yscale('log')
    plt.title('å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«åˆ†å¸ƒ', fontsize=12, fontweight='bold')
    plt.grid(True, alpha=0.3)
    
    # 3. ãƒ©ãƒ³ã‚¯-ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ãƒ—ãƒ­ãƒƒãƒˆ (log-log)
    ax3 = plt.subplot(3, 3, 3)
    plt.scatter(ranks, sorted_data, s=10, alpha=0.5, color='darkgreen')
    
    # å›å¸°ç›´ç·š
    log_ranks = np.log10(ranks)
    log_predicted = metrics['slope'] * log_ranks + metrics['intercept']
    predicted = 10 ** log_predicted
    plt.plot(ranks, predicted, 'r-', linewidth=2, 
             label=f'ã¹ãæ³•å‰‡ãƒ•ã‚£ãƒƒãƒˆ\nÎ±={metrics["alpha"]:.3f}\nRÂ²={metrics["r_squared"]:.4f}')
    
    plt.xscale('log')
    plt.yscale('log')
    plt.xlabel('ãƒ©ãƒ³ã‚¯ (log)', fontsize=11)
    plt.ylabel('ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•° (log)', fontsize=11)
    plt.title('ãƒ©ãƒ³ã‚¯-ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ãƒ—ãƒ­ãƒƒãƒˆ (log-log)', fontsize=12, fontweight='bold')
    plt.legend(fontsize=9)
    plt.grid(True, alpha=0.3)
    
    # 4. ç´¯ç©åˆ†å¸ƒé–¢æ•° (CCDF)
    ax4 = plt.subplot(3, 3, 4)
    unique_values = np.unique(sorted_data)
    ccdf = np.array([np.sum(data >= val) / len(data) for val in unique_values])
    
    plt.scatter(unique_values, ccdf, s=10, alpha=0.5, color='purple')
    plt.xscale('log')
    plt.yscale('log')
    plt.xlabel('ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•° (log)', fontsize=11)
    plt.ylabel('P(X â‰¥ x)', fontsize=11)
    plt.title('ç›¸è£œç´¯ç©åˆ†å¸ƒé–¢æ•° (CCDF)', fontsize=12, fontweight='bold')
    plt.grid(True, alpha=0.3)
    
    # 5. ãƒ­ãƒ¼ãƒ¬ãƒ³ãƒ„æ›²ç·š
    ax5 = plt.subplot(3, 3, 5)
    sorted_asc = np.sort(data)
    cumsum = np.cumsum(sorted_asc)
    cumsum_norm = cumsum / cumsum[-1]
    x = np.linspace(0, 1, len(cumsum_norm))
    
    plt.plot(x, cumsum_norm, linewidth=2, color='darkblue', label='ãƒ­ãƒ¼ãƒ¬ãƒ³ãƒ„æ›²ç·š')
    plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='å®Œå…¨å¹³ç­‰ç·š')
    
    plt.fill_between(x, cumsum_norm, x, alpha=0.3, color='skyblue')
    plt.xlabel('ç´¯ç©ã‚²ãƒ¼ãƒ å‰²åˆ', fontsize=11)
    plt.ylabel('ç´¯ç©ãƒ¬ãƒ“ãƒ¥ãƒ¼å‰²åˆ', fontsize=11)
    plt.title(f'ãƒ­ãƒ¼ãƒ¬ãƒ³ãƒ„æ›²ç·š (Gini={metrics["gini"]:.4f})', fontsize=12, fontweight='bold')
    plt.legend(fontsize=9)
    plt.grid(True, alpha=0.3)
    
    # 6. Q-Qãƒ—ãƒ­ãƒƒãƒˆ
    ax6 = plt.subplot(3, 3, 6)
    log_data = np.log10(sorted_data)
    theoretical_quantiles = np.linspace(log_data.min(), log_data.max(), len(log_data))
    
    plt.scatter(theoretical_quantiles, log_data, s=10, alpha=0.5, color='orange')
    plt.plot([log_data.min(), log_data.max()], 
             [log_data.min(), log_data.max()], 
             'r--', linewidth=2, label='ç†è«–ç›´ç·š')
    
    plt.xlabel('ç†è«–åˆ†ä½ç‚¹ (log)', fontsize=11)
    plt.ylabel('å®Ÿæ¸¬åˆ†ä½ç‚¹ (log)', fontsize=11)
    plt.title('Q-Qãƒ—ãƒ­ãƒƒãƒˆ (ã¹ãåˆ†å¸ƒ)', fontsize=12, fontweight='bold')
    plt.legend(fontsize=9)
    plt.grid(True, alpha=0.3)
    
    # 7. ä¸Šä½ã‚²ãƒ¼ãƒ ã®é›†ä¸­åº¦
    ax7 = plt.subplot(3, 3, 7)
    percentages = [1, 5, 10, 20, 50]
    contributions = [
        metrics['top_1_pct'] * 100,
        metrics['top_5_pct'] * 100,
        metrics['top_10_pct'] * 100,
        metrics['pareto_20'] * 100,
        np.sum(sorted_data[:int(len(data)*0.5)]) / np.sum(data) * 100
    ]
    
    bars = plt.bar(range(len(percentages)), contributions, 
                   color=['#d62728', '#ff7f0e', '#2ca02c', '#1f77b4', '#9467bd'],
                   edgecolor='black', linewidth=1.5)
    plt.xticks(range(len(percentages)), [f'ä¸Šä½{p}%' for p in percentages])
    plt.ylabel('ç·ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ã«å ã‚ã‚‹å‰²åˆ (%)', fontsize=11)
    plt.title('ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ã®é›†ä¸­åº¦', fontsize=12, fontweight='bold')
    plt.grid(True, alpha=0.3, axis='y')
    
    # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
    for bar, val in zip(bars, contributions):
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height,
                f'{val:.1f}%', ha='center', va='bottom', fontsize=9, fontweight='bold')
    
    # 8. æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ
    ax8 = plt.subplot(3, 3, 8)
    log_ranks = np.log10(ranks)
    log_values = np.log10(sorted_data)
    predicted_log = metrics['slope'] * log_ranks + metrics['intercept']
    residuals = log_values - predicted_log
    
    plt.scatter(log_ranks, residuals, s=10, alpha=0.5, color='brown')
    plt.axhline(y=0, color='r', linestyle='--', linewidth=2)
    plt.xlabel('log(ãƒ©ãƒ³ã‚¯)', fontsize=11)
    plt.ylabel('æ®‹å·®', fontsize=11)
    plt.title('æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ', fontsize=12, fontweight='bold')
    plt.grid(True, alpha=0.3)
    
    # 9. çµ±è¨ˆã‚µãƒãƒªãƒ¼
    ax9 = plt.subplot(3, 3, 9)
    ax9.axis('off')
    
    summary_text = f"""
ã€ã¹ãåˆ†å¸ƒåˆ†æçµæœã€‘

ã¹ãæŒ‡æ•° (Î±):     {metrics['alpha']:.3f}
æ±ºå®šä¿‚æ•° (RÂ²):    {metrics['r_squared']:.4f}
Giniä¿‚æ•°:         {metrics['gini']:.4f}

ã€é›†ä¸­åº¦ã€‘
ä¸Šä½  1%:  {metrics['top_1_pct']*100:>5.1f}%
ä¸Šä½  5%:  {metrics['top_5_pct']*100:>5.1f}%
ä¸Šä½ 10%:  {metrics['top_10_pct']*100:>5.1f}%
ä¸Šä½ 20%:  {metrics['pareto_20']*100:>5.1f}%

ã€åŸºæœ¬çµ±è¨ˆã€‘
ãƒ‡ãƒ¼ã‚¿æ•°:  {len(data):>10,}
æœ€å¤§å€¤:    {np.max(data):>10,}
å¹³å‡å€¤:    {np.mean(data):>10,.1f}
ä¸­å¤®å€¤:    {np.median(data):>10,.0f}
åˆè¨ˆ:      {np.sum(data):>10,}
    """
    
    plt.text(0.1, 0.9, summary_text, transform=ax9.transAxes,
             fontsize=10, verticalalignment='top', fontfamily='monospace',
             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
    
    plt.suptitle('Steamãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ã®ã¹ãåˆ†å¸ƒåˆ†æ', fontsize=16, fontweight='bold', y=0.995)
    plt.tight_layout()
    
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"ğŸ“Š ã‚°ãƒ©ãƒ•ä¿å­˜: {output_path}")
    
    return fig


def evaluate_power_law(metrics):
    """ã¹ãåˆ†å¸ƒã¸ã®é©åˆåº¦ã‚’è©•ä¾¡"""
    
    print("\n" + "="*70)
    print("ğŸ“ˆ ã¹ãåˆ†å¸ƒé©åˆåº¦ã®è©•ä¾¡")
    print("="*70)
    
    score = 0
    max_score = 5
    
    # 1. RÂ²ã®è©•ä¾¡
    print(f"\n1ï¸âƒ£  æ±ºå®šä¿‚æ•° (RÂ²): {metrics['r_squared']:.4f}")
    if metrics['r_squared'] > 0.95:
        print("   âœ… éå¸¸ã«è‰¯å¥½ãªé©åˆ (RÂ² > 0.95)")
        score += 1
    elif metrics['r_squared'] > 0.90:
        print("   âœ… è‰¯å¥½ãªé©åˆ (RÂ² > 0.90)")
        score += 0.8
    elif metrics['r_squared'] > 0.80:
        print("   âš ï¸  ã‚„ã‚„å¼±ã„é©åˆ (RÂ² > 0.80)")
        score += 0.5
    else:
        print("   âŒ é©åˆãŒå¼±ã„")
    
    # 2. Î±ã®ç¯„å›²
    print(f"\n2ï¸âƒ£  ã¹ãæŒ‡æ•° (Î±): {metrics['alpha']:.3f}")
    if 1.0 < metrics['alpha'] < 3.0:
        print("   âœ… å…¸å‹çš„ãªã¹ãåˆ†å¸ƒã®ç¯„å›² (1 < Î± < 3)")
        score += 1
    elif 0.5 < metrics['alpha'] <= 1.0:
        print("   âš ï¸  æ¥µç«¯ãªä¸å¹³ç­‰ (Î± â‰¤ 1)")
        score += 0.7
    elif 3.0 <= metrics['alpha'] < 4.0:
        print("   âš ï¸  ã‚„ã‚„å‡ç­‰å¯„ã‚Š (Î± â‰¥ 3)")
        score += 0.5
    else:
        print("   âŒ å…¸å‹çš„ãªç¯„å›²å¤–")
    
    # 3. Giniä¿‚æ•°
    print(f"\n3ï¸âƒ£  Giniä¿‚æ•°: {metrics['gini']:.4f}")
    if metrics['gini'] > 0.8:
        print("   âœ… æ¥µç«¯ãªä¸å¹³ç­‰ (ã¹ãåˆ†å¸ƒçš„)")
        score += 1
    elif metrics['gini'] > 0.6:
        print("   âœ… é«˜ã„ä¸å¹³ç­‰")
        score += 0.7
    else:
        print("   âš ï¸  ã‚„ã‚„å‡ç­‰")
        score += 0.3
    
    # 4. ãƒ‘ãƒ¬ãƒ¼ãƒˆåˆ†æ
    print(f"\n4ï¸âƒ£  ãƒ‘ãƒ¬ãƒ¼ãƒˆåˆ†æ (ä¸Šä½20%): {metrics['pareto_20']*100:.1f}%")
    if metrics['pareto_20'] > 0.8:
        print("   âœ… ãƒ‘ãƒ¬ãƒ¼ãƒˆã®æ³•å‰‡ã‚’å¤§ããè¶…ãˆã‚‹ (>80%)")
        score += 1
    elif metrics['pareto_20'] > 0.7:
        print("   âœ… ãƒ‘ãƒ¬ãƒ¼ãƒˆã®æ³•å‰‡ã«è¿‘ã„")
        score += 0.8
    else:
        print("   âš ï¸  ãƒ‘ãƒ¬ãƒ¼ãƒˆã®æ³•å‰‡ã»ã©æ¥µç«¯ã§ã¯ãªã„")
        score += 0.5
    
    # 5. é›†ä¸­åº¦ã®æ¥µç«¯ã•
    print(f"\n5ï¸âƒ£  ä¸Šä½1%ã®é›†ä¸­åº¦: {metrics['top_1_pct']*100:.1f}%")
    if metrics['top_1_pct'] > 0.5:
        print("   âœ… æ¥µç«¯ãªé›†ä¸­ (>50%)")
        score += 1
    elif metrics['top_1_pct'] > 0.3:
        print("   âœ… é«˜ã„é›†ä¸­")
        score += 0.7
    else:
        print("   âš ï¸  ã‚„ã‚„åˆ†æ•£")
        score += 0.3
    
    # ç·åˆè©•ä¾¡
    print("\n" + "="*70)
    print(f"ğŸ“Š ç·åˆã‚¹ã‚³ã‚¢: {score:.1f} / {max_score}")
    print("="*70)
    
    if score >= 4.5:
        print("âœ… çµè«–: ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ã¯éå¸¸ã«å¼·ã„ã¹ãåˆ†å¸ƒã«å¾“ã£ã¦ã„ã¾ã™")
    elif score >= 3.5:
        print("âœ… çµè«–: ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ã¯æ˜ç¢ºãªã¹ãåˆ†å¸ƒã«å¾“ã£ã¦ã„ã¾ã™")
    elif score >= 2.5:
        print("âš ï¸  çµè«–: ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ã¯ã¹ãåˆ†å¸ƒçš„ãªå‚¾å‘ãŒã‚ã‚Šã¾ã™ãŒã€ã‚„ã‚„å¼±ã„ã§ã™")
    else:
        print("âŒ çµè«–: ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ã¯ã¹ãåˆ†å¸ƒã«å¾“ã£ã¦ã„ã‚‹ã¨ã¯è¨€ãˆã¾ã›ã‚“")
    
    print("="*70)


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    
    # CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    csv_file = Path(__file__).parent.parent / 'data' / 'steam_simple_49847_20260118_182744.csv'
    
    if not csv_file.exists():
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_file}")
        return
    
    print("="*70)
    print("ğŸ® Steam ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ã¹ãåˆ†å¸ƒåˆ†æ")
    print("="*70)
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    reviews = load_review_data(csv_file)
    
    if len(reviews) == 0:
        print("âŒ ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # åŸºæœ¬çµ±è¨ˆ
    print("\nğŸ“Š åŸºæœ¬çµ±è¨ˆ:")
    print(f"  ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚ã‚Šã‚²ãƒ¼ãƒ æ•°: {len(reviews):,}")
    print(f"  æœ€å¤§ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°:       {np.max(reviews):,}")
    print(f"  æœ€å°ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°:       {np.min(reviews):,}")
    print(f"  å¹³å‡ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°:       {np.mean(reviews):,.1f}")
    print(f"  ä¸­å¤®å€¤:               {np.median(reviews):,.0f}")
    print(f"  ç·ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°:         {np.sum(reviews):,}")
    
    # ã¹ãåˆ†å¸ƒåˆ†æ
    print("\nğŸ” ã¹ãåˆ†å¸ƒåˆ†æã‚’å®Ÿè¡Œä¸­...")
    metrics = calculate_power_law_metrics(reviews)
    
    # ã‚°ãƒ©ãƒ•ä½œæˆ
    output_path = Path(__file__).parent.parent / 'review_power_law_analysis.png'
    create_analysis_plots(reviews, metrics, output_path)
    
    # è©•ä¾¡
    evaluate_power_law(metrics)
    
    print(f"\nâœ… åˆ†æå®Œäº†ï¼")
    print(f"ğŸ“Š ã‚°ãƒ©ãƒ•: {output_path}")


if __name__ == "__main__":
    main()
